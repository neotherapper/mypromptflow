# Compression Patterns - Research-Specific Algorithms
# SuperClaude 70% token reduction through intelligent pattern compression

compression_patterns:
  version: "1.0"
  description: "Research-specific compression algorithms and patterns"
  
  # Core Research Compression Algorithms
  research_algorithms:
    methodology_compression:
      name: "Research Methodology Compression"
      target_reduction: "70%"
      pattern_structure: "Method → Steps → Validation → Outcome"
      
      compression_rules:
        method_identification:
          original: "The research methodology employed in this study"
          compressed: "🔬 Method:"
          reduction: "85%"
        
        step_enumeration:
          original: "The following steps were performed in sequence"
          compressed: "Steps: 1→2→3→4"
          reduction: "78%"
        
        validation_process:
          original: "Validation was conducted through peer review and testing"
          compressed: "✅ Validation: peer review + testing"
          reduction: "72%"
        
        outcome_summary:
          original: "The results demonstrate significant improvement"
          compressed: "📊 Results: ⬆️ significant improvement"
          reduction: "68%"
      
      algorithm_steps:
        1: "Identify methodology keywords"
        2: "Extract core process steps"
        3: "Compress validation methods"
        4: "Summarize outcomes with symbols"
        5: "Validate information completeness"
    
    findings_synthesis:
      name: "Research Findings Synthesis"
      target_reduction: "65%"
      pattern_structure: "Discovery → Analysis → Implications → Recommendations"
      
      compression_rules:
        discovery_identification:
          original: "The key finding from this research indicates"
          compressed: "💡 Finding:"
          reduction: "82%"
        
        analysis_compression:
          original: "Analysis of the data reveals several patterns"
          compressed: "📊 Analysis: patterns identified"
          reduction: "75%"
        
        implications_summary:
          original: "The implications of these findings for future research"
          compressed: "→ Implications: future research"
          reduction: "78%"
        
        recommendations_list:
          original: "Based on these findings, we recommend the following"
          compressed: "💭 Recommendations:"
          reduction: "80%"
      
      algorithm_steps:
        1: "Extract key discoveries"
        2: "Compress analytical insights"
        3: "Summarize implications"
        4: "List recommendations concisely"
        5: "Validate completeness"
    
    literature_review_compression:
      name: "Literature Review Compression"
      target_reduction: "60%"
      pattern_structure: "Sources → Synthesis → Gaps → Integration"
      
      compression_rules:
        source_citation:
          original: "According to Smith et al. (2023), the research demonstrates"
          compressed: "Smith+ (2023): research shows"
          reduction: "70%"
        
        synthesis_patterns:
          original: "The synthesis of existing literature reveals"
          compressed: "📚 Synthesis:"
          reduction: "85%"
        
        gap_identification:
          original: "A significant gap exists in the current literature"
          compressed: "🔍 Gap: current literature"
          reduction: "76%"
        
        integration_summary:
          original: "Integration of these findings into the broader context"
          compressed: "🔄 Integration: broader context"
          reduction: "73%"
      
      algorithm_steps:
        1: "Compress citation formats"
        2: "Synthesize key themes"
        3: "Identify research gaps"
        4: "Integrate findings"
        5: "Validate coverage"

  # Symbol-Based Research Notation
  research_symbol_patterns:
    research_process_flow:
      planning: "📋 Plan:"
      execution: "⚡ Execute:"
      analysis: "📊 Analyze:"
      validation: "✅ Validate:"
      documentation: "📝 Document:"
      
      flow_notation:
        sequential: "📋 → ⚡ → 📊 → ✅ → 📝"
        parallel: "📋 ∧ (⚡ ∧ 📊) → ✅ → 📝"
        iterative: "📋 → (⚡ ↔ 📊) → ✅ → 📝"
        conditional: "📋 → ⚡ → (📊 ∨ 🔄) → ✅"
    
    research_quality_indicators:
      high_confidence: "🟢"
      medium_confidence: "🟡"
      low_confidence: "🔴"
      verified: "✅"
      unverified: "❓"
      needs_review: "⚠️"
      
      quality_patterns:
        high_quality: "🟢 ✅ High-quality research"
        medium_quality: "🟡 ✅ Moderate-quality research"
        low_quality: "🔴 ❓ Low-quality research"
        pending_review: "⚠️ ❓ Pending review"
    
    research_relationship_mapping:
      builds_on: "⊃"
      extends: "→"
      contradicts: "⊥"
      supports: "↑"
      questions: "❓"
      validates: "✅"
      
      relationship_patterns:
        supportive: "Research A ↑ Research B"
        contradictory: "Research A ⊥ Research B"
        foundational: "Research A ⊃ Research B"
        sequential: "Research A → Research B"

  # Progressive Detail Compression
  progressive_compression:
    level_1_minimal:
      research_summary:
        template: "🔬 [Method] → 📊 [Key Finding] → 💭 [Recommendation]"
        token_budget: "50-100 tokens"
        information_density: "Critical insights only"
        
        example:
          original: "This quantitative research study employed a survey methodology to investigate user preferences in AI interfaces. The analysis of 500 responses revealed that 78% of users prefer conversational interfaces over traditional menu-based systems. Based on these findings, we recommend prioritizing conversational AI development in future product iterations."
          compressed: "🔬 Survey (n=500) → 📊 78% prefer conversational AI → 💭 Prioritize conversational development"
          reduction: "85%"
    
    level_2_basic:
      research_summary:
        template: "🔬 [Method + Context] → 📊 [Findings + Analysis] → 💭 [Detailed Recommendations]"
        token_budget: "100-200 tokens"
        information_density: "Core insights + context"
        
        example:
          original: "This quantitative research study employed a survey methodology to investigate user preferences in AI interfaces across different demographic groups. The analysis of 500 responses from users aged 18-65 revealed that 78% prefer conversational interfaces, with higher preferences among younger users (85% for 18-35 vs 65% for 45-65). Based on these findings, we recommend prioritizing conversational AI development while ensuring accessibility for older users."
          compressed: "🔬 Survey study (n=500, age 18-65) examined AI interface preferences → 📊 78% prefer conversational (85% young, 65% older) → 💭 Prioritize conversational AI + accessibility for older users"
          reduction: "70%"
    
    level_3_moderate:
      research_summary:
        template: "🔬 [Complete Method] → 📊 [Comprehensive Analysis] → 💭 [Strategic Recommendations]"
        token_budget: "200-400 tokens"
        information_density: "Full context + implications"
        
        example:
          original: "This quantitative research study employed a comprehensive survey methodology to investigate user preferences in AI interfaces across different demographic groups and usage contexts. The analysis of 500 responses from users aged 18-65 across various industries revealed that 78% prefer conversational interfaces over traditional menu-based systems, with significantly higher preferences among younger users (85% for 18-35 vs 65% for 45-65) and technology sector workers (82% vs 71% average). The findings suggest that conversational AI adoption is driven by familiarity with modern communication tools and professional technology exposure. Based on these findings, we recommend prioritizing conversational AI development while ensuring accessibility features for older users and providing training resources for traditional interface users."
          compressed: "🔬 Survey study (n=500, age 18-65, multi-industry) investigated AI interface preferences by demographics + usage context → 📊 78% prefer conversational AI (85% young vs 65% older, 82% tech sector vs 71% average). Conversational adoption driven by modern communication familiarity + tech exposure → 💭 Prioritize conversational AI development + accessibility for older users + training for traditional interface users"
          reduction: "65%"

  # Context-Aware Optimization Rules
  context_optimization_rules:
    domain_specific_compression:
      ai_research:
        keywords: ["AI", "ML", "NLP", "neural", "training", "inference"]
        symbol_priority: ["🤖", "🧠", "🕸️", "🔮", "🏋️"]
        compression_focus: "Technical processes and outcomes"
        average_reduction: "72%"
      
      software_engineering:
        keywords: ["code", "API", "framework", "deployment", "testing"]
        symbol_priority: ["⚙️", "🔌", "🚀", "🧪", "🔧"]
        compression_focus: "Implementation and architecture"
        average_reduction: "68%"
      
      business_analysis:
        keywords: ["strategy", "KPI", "ROI", "stakeholder", "process"]
        symbol_priority: ["🎯", "📊", "💰", "👥", "🔄"]
        compression_focus: "Metrics and strategic outcomes"
        average_reduction: "65%"
      
      academic_research:
        keywords: ["methodology", "hypothesis", "validation", "peer-review"]
        symbol_priority: ["🔬", "❓", "✅", "👥", "📚"]
        compression_focus: "Research rigor and findings"
        average_reduction: "70%"
    
    complexity_based_optimization:
      simple_concepts:
        threshold: "Single domain, linear process"
        compression_strategy: "Basic symbol substitution"
        target_reduction: "50-60%"
      
      moderate_concepts:
        threshold: "Multi-step process, some dependencies"
        compression_strategy: "Symbol combinations + flow notation"
        target_reduction: "60-70%"
      
      complex_concepts:
        threshold: "Multi-domain, complex relationships"
        compression_strategy: "Advanced symbol patterns + hierarchical compression"
        target_reduction: "70-80%"
      
      expert_concepts:
        threshold: "Highly specialized, dense information"
        compression_strategy: "Domain-specific symbols + algorithmic compression"
        target_reduction: "75-85%"
    
    user_expertise_adaptation:
      novice_users:
        compression_level: "Conservative (50-60%)"
        symbol_usage: "Basic symbols only"
        explanation_level: "Detailed context preserved"
        quality_threshold: "95% completeness"
      
      intermediate_users:
        compression_level: "Moderate (60-70%)"
        symbol_usage: "Standard symbol set"
        explanation_level: "Core context preserved"
        quality_threshold: "90% completeness"
      
      expert_users:
        compression_level: "Aggressive (70-80%)"
        symbol_usage: "Advanced symbol patterns"
        explanation_level: "Minimal context needed"
        quality_threshold: "85% completeness"
      
      specialist_users:
        compression_level: "Maximum (75-85%)"
        symbol_usage: "Domain-specific symbols"
        explanation_level: "Expert-level assumptions"
        quality_threshold: "80% completeness"

  # Quality Preservation Algorithms
  quality_preservation:
    information_completeness:
      essential_elements:
        - "Core research question"
        - "Primary methodology"
        - "Key findings"
        - "Main conclusions"
        - "Critical recommendations"
      
      preservation_priority:
        1: "Research objectives and questions"
        2: "Methodology and approach"
        3: "Primary findings and results"
        4: "Key conclusions and implications"
        5: "Supporting evidence and details"
      
      validation_metrics:
        completeness_score: "Essential elements present / Total essential elements"
        accuracy_score: "Correct information / Total information"
        clarity_score: "Understandable elements / Total elements"
        usability_score: "Actionable insights / Total insights"
    
    accuracy_preservation:
      fact_checking:
        numerical_data: "Exact values preserved"
        statistical_results: "Significance levels maintained"
        categorical_data: "Categories accurately represented"
        temporal_data: "Time relationships preserved"
      
      relationship_preservation:
        causal_relationships: "Cause-effect maintained"
        correlational_data: "Correlation strength preserved"
        hierarchical_structures: "Hierarchy levels maintained"
        sequential_processes: "Order and dependencies preserved"
      
      context_preservation:
        domain_context: "Field-specific meaning maintained"
        methodological_context: "Research approach implications preserved"
        temporal_context: "Time-sensitive information maintained"
        cultural_context: "Cultural implications preserved"
    
    readability_optimization:
      symbol_familiarity:
        introduction_strategy: "Gradual symbol introduction"
        learning_support: "Symbol reference availability"
        context_clues: "Symbol meaning from context"
        fallback_options: "Text alternatives available"
      
      structure_clarity:
        logical_flow: "Information follows logical sequence"
        visual_hierarchy: "Important information emphasized"
        chunk_organization: "Related information grouped"
        navigation_aids: "Clear section markers"
      
      comprehension_support:
        key_concept_highlighting: "Critical information emphasized"
        relationship_mapping: "Connections made explicit"
        summary_provision: "Key takeaways clearly stated"
        example_integration: "Concrete examples provided"

  # Performance Optimization
  performance_optimization:
    compression_speed:
      algorithm_efficiency:
        pattern_recognition: "O(n) time complexity"
        symbol_substitution: "O(1) lookup time"
        quality_validation: "O(n) validation time"
        overall_performance: "Real-time compression capability"
      
      caching_strategies:
        pattern_cache: "Frequently used patterns cached"
        symbol_cache: "Symbol mappings cached"
        quality_cache: "Quality metrics cached"
        user_preference_cache: "User preferences cached"
      
      parallel_processing:
        pattern_detection: "Parallel pattern recognition"
        symbol_application: "Parallel symbol substitution"
        quality_checking: "Parallel quality validation"
        output_generation: "Parallel output formatting"
    
    memory_optimization:
      data_structures:
        pattern_storage: "Efficient pattern data structures"
        symbol_mapping: "Optimized symbol tables"
        cache_management: "Memory-efficient caching"
        garbage_collection: "Automatic memory cleanup"
      
      resource_utilization:
        cpu_optimization: "Efficient algorithm implementation"
        memory_optimization: "Minimal memory footprint"
        io_optimization: "Efficient file operations"
        network_optimization: "Optimized data transfer"
    
    scalability_considerations:
      horizontal_scaling:
        distributed_processing: "Multi-node compression"
        load_balancing: "Workload distribution"
        fault_tolerance: "Error recovery mechanisms"
        performance_monitoring: "Real-time performance tracking"
      
      vertical_scaling:
        resource_scaling: "Dynamic resource allocation"
        performance_tuning: "Adaptive optimization"
        capacity_planning: "Predictive scaling"
        bottleneck_identification: "Performance bottleneck detection"

  # Integration Patterns
  integration_patterns:
    workflow_integration:
      preprocessing: "Context analysis and pattern selection"
      processing: "Compression algorithm application"
      postprocessing: "Quality validation and optimization"
      feedback: "Performance monitoring and improvement"
    
    api_integration:
      compression_endpoint: "/api/compress"
      pattern_endpoint: "/api/patterns"
      quality_endpoint: "/api/quality"
      feedback_endpoint: "/api/feedback"
    
    system_integration:
      document_generation: "Seamless compression integration"
      workflow_orchestration: "Automated compression triggers"
      quality_assurance: "Continuous quality monitoring"
      user_interface: "Transparent compression experience"
    
    data_integration:
      input_formats: "Multiple input format support"
      output_formats: "Flexible output generation"
      metadata_handling: "Compression metadata preservation"
      version_control: "Compression version tracking"

  # Continuous Improvement
  continuous_improvement:
    learning_mechanisms:
      pattern_learning: "New pattern discovery"
      user_feedback: "User preference learning"
      performance_learning: "Performance optimization learning"
      quality_learning: "Quality improvement learning"
    
    adaptation_strategies:
      real_time_adaptation: "Dynamic pattern adjustment"
      batch_adaptation: "Periodic pattern updates"
      user_adaptation: "Personalized compression strategies"
      domain_adaptation: "Domain-specific optimization"
    
    feedback_loops:
      user_feedback: "User satisfaction and preference feedback"
      system_feedback: "Performance and quality metrics"
      expert_feedback: "Expert evaluation and guidance"
      automated_feedback: "Automated quality assessment"
    
    improvement_metrics:
      compression_efficiency: "Compression ratio improvements"
      quality_preservation: "Quality metric improvements"
      user_satisfaction: "User satisfaction score improvements"
      system_performance: "System performance improvements"