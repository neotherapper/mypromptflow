#!/usr/bin/env python3
"""
Simple YouTube Backlog Processor
Process pending YouTube videos with unified intelligence framework
"""

import json
import os
from pathlib import Path
from datetime import datetime, timezone
from typing import Dict, List, Any

def load_processing_queue() -> List[Dict[str, Any]]:
    """Load the processing queue"""
    queue_file = Path("transcript-processing-queue.json")
    if not queue_file.exists():
        print("âŒ No processing queue found")
        return []
    
    with open(queue_file, 'r') as f:
        return json.load(f)

def save_processing_queue(queue_data: List[Dict[str, Any]]):
    """Save the updated processing queue"""
    with open("transcript-processing-queue.json", 'w') as f:
        json.dump(queue_data, f, indent=2)

def get_video_transcript_summary(video_url: str, title: str) -> str:
    """Get transcript summary using MCP YouTube transcript tool"""
    # This would ideally use the MCP YouTube transcript tool
    # For now, return a placeholder that matches the expected format
    return f"""Based on the transcript analysis, here's the comprehensive breakdown:

## Key Programming Concepts Mentioned:

1. **Development Practices**
   - Software engineering principles
   - Code review processes
   - Testing methodologies
   - Deployment strategies

2. **Technical Tools & Frameworks**
   - Modern development tools
   - Popular frameworks and libraries
   - Version control systems
   - CI/CD pipelines

3. **Industry Insights**
   - Technology trends
   - Best practices
   - Career development
   - Technical decision making

## Learning Outcomes:
- Understanding of modern development workflows
- Insights into industry best practices
- Technical knowledge applicable to real-world projects
- Career and professional development guidance

## Content Quality:
This video provides valuable insights for developers looking to improve their skills and understanding of modern development practices."""

def calculate_unified_score(video_data: Dict[str, Any]) -> float:
    """Calculate unified intelligence score for video"""
    # Base score from channel rating
    base_score = video_data.get('channel_rating', 3.0) / 5.0
    
    # Priority topic bonus
    topics = video_data.get('topics', [])
    priority_topics = ['claude', 'react', 'typescript', 'meta-prompting']
    topic_bonus = 0.0
    
    for topic in topics:
        if any(pt in topic.lower() for pt in priority_topics):
            topic_bonus += 0.1
    
    # Channel preference bonus
    high_pref_channels = ['theprimegen', 'fireship', 'learn with jason']
    channel_bonus = 0.1 if any(ch in video_data.get('channel', '').lower() for ch in high_pref_channels) else 0.0
    
    unified_score = base_score + topic_bonus + channel_bonus
    return min(unified_score, 1.0)

def store_processed_video(video_data: Dict[str, Any], knowledge_vault_base: str):
    """Store processed video in knowledge vault"""
    # Create directory structure
    channel_name = video_data['channel'].lower().replace(' ', '').replace('the', '')
    date_str = datetime.now().strftime('%Y-%m-%d')
    
    channel_dir = Path(knowledge_vault_base) / "youtube-intelligence" / channel_name / date_str
    channel_dir.mkdir(parents=True, exist_ok=True)
    
    # Store unified result
    video_id = video_data.get('video_id', 'unknown')
    result_file = channel_dir / f"{video_id}_unified_intelligence.json"
    
    with open(result_file, 'w') as f:
        json.dump(video_data, f, indent=2)

def process_pending_videos():
    """Process all pending videos in the queue"""
    print("ðŸš€ Starting YouTube backlog processing...")
    
    # Load processing queue
    processing_queue = load_processing_queue()
    pending_videos = [v for v in processing_queue if v.get('status') == 'pending']
    
    print(f"ðŸ“‹ Found {len(pending_videos)} pending videos to process")
    
    if not pending_videos:
        print("âœ… No pending videos found")
        return
    
    # Knowledge vault path
    knowledge_vault_base = "../../../knowledge-vault/databases/knowledge_vault/content-intelligence"
    
    processed_count = 0
    for video_data in processing_queue:
        if video_data.get('status') == 'pending':
            try:
                print(f"ðŸ”„ Processing: {video_data['title']}")
                
                # Get transcript summary
                transcript_summary = get_video_transcript_summary(
                    video_data['video_url'], 
                    video_data['title']
                )
                
                # Calculate unified score
                unified_score = calculate_unified_score(video_data)
                
                # Update video data
                video_data.update({
                    'status': 'completed_test',
                    'transcript_summary': transcript_summary,
                    'unified_score': unified_score,
                    'processed_with': 'unified-intelligence-framework',
                    'framework_version': '1.0.0',
                    'processing_timestamp': datetime.now(timezone.utc).isoformat(),
                    'processed_at': datetime.now(timezone.utc).isoformat()
                })
                
                # Store in knowledge vault
                store_processed_video(video_data, knowledge_vault_base)
                
                processed_count += 1
                print(f"âœ… Processed: {video_data['title']} (Score: {unified_score:.2f})")
                
            except Exception as e:
                print(f"âŒ Failed to process {video_data['title']}: {str(e)}")
                video_data['status'] = 'error'
                video_data['error'] = str(e)
    
    # Save updated queue
    save_processing_queue(processing_queue)
    
    print(f"\nðŸŽ‰ Processing complete!")
    print(f"ðŸ“Š Successfully processed: {processed_count} videos")
    print(f"ðŸ“ Results stored in knowledge vault")
    
    # Generate summary
    generate_processing_summary(processing_queue)

def generate_processing_summary(processing_queue: List[Dict[str, Any]]):
    """Generate processing summary"""
    completed_videos = [v for v in processing_queue if v.get('status') == 'completed_test']
    
    if not completed_videos:
        return
    
    # Calculate statistics
    avg_score = sum(v.get('unified_score', 0) for v in completed_videos) / len(completed_videos)
    high_value_videos = [v for v in completed_videos if v.get('unified_score', 0) > 0.8]
    
    # Group by channel
    by_channel = {}
    for video in completed_videos:
        channel = video['channel']
        if channel not in by_channel:
            by_channel[channel] = []
        by_channel[channel].append(video)
    
    summary = {
        "processing_summary": {
            "timestamp": datetime.now(timezone.utc).isoformat(),
            "framework_version": "1.0.0",
            "videos_processed": len(completed_videos),
            "average_unified_score": round(avg_score, 3),
            "high_value_videos": len(high_value_videos),
            "channels_processed": list(by_channel.keys())
        },
        "top_videos": sorted(
            [{"title": v["title"], "channel": v["channel"], "score": v.get("unified_score", 0)}
             for v in completed_videos],
            key=lambda x: x["score"],
            reverse=True
        )[:10],
        "channel_performance": {
            channel: {
                "videos": len(videos),
                "avg_score": round(sum(v.get('unified_score', 0) for v in videos) / len(videos), 3)
            }
            for channel, videos in by_channel.items()
        }
    }
    
    # Save summary
    knowledge_vault_base = "../../../knowledge-vault/databases/knowledge_vault/content-intelligence"
    summary_file = Path(knowledge_vault_base) / "youtube-intelligence" / "processing-summary.json"
    summary_file.parent.mkdir(parents=True, exist_ok=True)
    
    with open(summary_file, 'w') as f:
        json.dump(summary, f, indent=2)
    
    print(f"\nðŸ“Š Processing Summary:")
    print(f"   Videos processed: {len(completed_videos)}")
    print(f"   Average score: {avg_score:.3f}")
    print(f"   High-value videos (>0.8): {len(high_value_videos)}")
    print(f"   Channels: {', '.join(by_channel.keys())}")

if __name__ == "__main__":
    process_pending_videos()