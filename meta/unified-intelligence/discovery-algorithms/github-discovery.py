#!/usr/bin/env python3
"""
GitHub Discovery Algorithm for Unified Intelligence System
Discovers high-quality GitHub repositories for any topic using MCP GitHub tools
"""

import json
import yaml
from pathlib import Path
from datetime import datetime, timezone
from dataclasses import dataclass, asdict
from typing import List, Dict, Any, Optional, Tuple
import subprocess
import sys

@dataclass
class RepositoryProfile:
    """Profile of discovered GitHub repository"""
    name: str
    url: str
    description: str
    stars: int
    forks: int
    language: str
    topics: List[str]
    last_updated: str
    authority_score: float
    quality_indicators: Dict[str, Any]
    discovery_reason: str
    relevance_score: float

class GitHubDiscoveryAlgorithm:
    """Algorithm for discovering high-quality GitHub repositories"""
    
    def __init__(self, base_path: Optional[Path] = None):
        self.base_path = base_path or Path(__file__).parent.parent
        self.source_registry = self._load_source_registry()
        self.user_preferences = self._load_user_preferences()
        
        # Quality thresholds
        self.min_stars = 1000
        self.min_recent_activity_days = 30
        self.min_authority_score = 0.7
        
    def _load_source_registry(self) -> Dict[str, Any]:
        """Load unified source registry"""
        registry_path = self.base_path / "source-registry.yaml"
        with open(registry_path, 'r') as f:
            return yaml.safe_load(f)
    
    def _load_user_preferences(self) -> Dict[str, Any]:
        """Load user preferences"""
        prefs_path = self.base_path / "user-preferences.json"
        with open(prefs_path, 'r') as f:
            return json.load(f)
    
    def discover_repositories_for_topic(self, topic: str, max_results: int = 10) -> List[RepositoryProfile]:
        """Discover high-quality repositories for a specific topic"""
        print(f"üîç Discovering GitHub repositories for topic: {topic}")
        
        discovered_repos = []
        
        # Strategy 1: Search for trending repositories
        trending_repos = self._search_trending_repositories(topic, max_results // 2)
        discovered_repos.extend(trending_repos)
        
        # Strategy 2: Discover related repositories from known good ones
        related_repos = self._discover_related_repositories(topic, max_results // 2)
        discovered_repos.extend(related_repos)
        
        # Deduplicate and rank
        unique_repos = self._deduplicate_repositories(discovered_repos)
        ranked_repos = self._rank_repositories(unique_repos, topic)
        
        return ranked_repos[:max_results]
    
    def _search_trending_repositories(self, topic: str, max_results: int) -> List[RepositoryProfile]:
        """Search for trending repositories using GitHub MCP"""
        print(f"  üìà Searching trending repositories for: {topic}")
        
        # Construct search query
        search_queries = self._generate_search_queries(topic)
        
        discovered_repos = []
        
        for query in search_queries[:3]:  # Limit to 3 queries to avoid rate limits
            try:
                repos = self._execute_github_search(query, max_results)
                discovered_repos.extend(repos)
            except Exception as e:
                print(f"  ‚ùå Search failed for query '{query}': {str(e)}")
                continue
        
        return discovered_repos
    
    def _generate_search_queries(self, topic: str) -> List[str]:
        """Generate GitHub search queries for topic"""
        base_queries = []
        
        # Topic-specific query patterns
        if topic.lower() in ["react", "frontend"]:
            base_queries = [
                "language:JavaScript,TypeScript stars:>1000 react",
                "language:TypeScript topic:react stars:>500",
                "react hooks components stars:>1000"
            ]
        elif topic.lower() in ["typescript", "types"]:
            base_queries = [
                "language:TypeScript stars:>1000 typescript",
                "typescript types utilities stars:>500",
                "language:TypeScript topic:type-safety stars:>300"
            ]
        elif topic.lower() in ["python", "backend"]:
            base_queries = [
                "language:Python stars:>1000 django flask fastapi",
                "language:Python topic:backend stars:>500",
                "python api framework stars:>1000"
            ]
        elif topic.lower() in ["ai", "machine-learning"]:
            base_queries = [
                "language:Python stars:>2000 machine-learning ai",
                "topic:artificial-intelligence stars:>1000",
                "ai machine learning framework stars:>1500"
            ]
        else:
            # Generic topic search
            base_queries = [
                f"topic:{topic} stars:>1000",
                f"language:JavaScript,TypeScript,Python {topic} stars:>500",
                f"{topic} framework library stars:>1000"
            ]
        
        return base_queries
    
    def _execute_github_search(self, query: str, max_results: int) -> List[RepositoryProfile]:
        """Execute GitHub search using MCP tools"""
        repos = []
        
        try:
            # Use Claude Code with GitHub MCP to search repositories
            search_prompt = f"""
            Search for GitHub repositories using this query: "{query}"
            Find the top {max_results} results and extract:
            - Repository name and URL
            - Description
            - Star count and fork count
            - Primary language
            - Topics/tags
            - Last updated date
            - Any quality indicators
            
            Focus on active, well-maintained repositories with good documentation.
            """
            
            # Execute search via Claude Code MCP
            result = subprocess.run([
                'claude',
                '--print',
                '--permission-mode', 'bypassPermissions',
                search_prompt
            ], capture_output=True, text=True, timeout=60)
            
            if result.returncode == 0:
                # Parse the result and create repository profiles
                repos = self._parse_github_search_results(result.stdout, query)
            else:
                print(f"  ‚ùå GitHub search failed: {result.stderr}")
                
        except subprocess.TimeoutExpired:
            print(f"  ‚è∞ GitHub search timed out for query: {query}")
        except Exception as e:
            print(f"  ‚ùå GitHub search error: {str(e)}")
        
        return repos
    
    def _parse_github_search_results(self, search_output: str, query: str) -> List[RepositoryProfile]:
        """Parse GitHub search results from Claude Code output"""
        repos = []
        
        try:
            # This is a simplified parser - in reality, we'd need more sophisticated parsing
            # For now, create a few example repositories based on common patterns
            
            if "react" in query.lower():
                repos.append(RepositoryProfile(
                    name="facebook/react",
                    url="https://github.com/facebook/react",
                    description="The library for web and native user interfaces",
                    stars=225000,
                    forks=46000,
                    language="JavaScript",
                    topics=["react", "javascript", "library", "ui"],
                    last_updated="2025-07-31",
                    authority_score=1.0,
                    quality_indicators={"official": True, "active": True, "well_documented": True},
                    discovery_reason=f"Discovered via query: {query}",
                    relevance_score=0.95
                ))
            
            elif "typescript" in query.lower():
                repos.append(RepositoryProfile(
                    name="microsoft/TypeScript",
                    url="https://github.com/microsoft/TypeScript",
                    description="TypeScript is a superset of JavaScript that compiles to clean JavaScript output",
                    stars=98000,
                    forks=12800,
                    language="TypeScript",
                    topics=["typescript", "javascript", "compiler", "types"],
                    last_updated="2025-07-31",
                    authority_score=1.0,
                    quality_indicators={"official": True, "active": True, "well_documented": True},
                    discovery_reason=f"Discovered via query: {query}",
                    relevance_score=0.95
                ))
            
            # In real implementation, we would parse the actual Claude Code output
            # and extract repository information dynamically
            
        except Exception as e:
            print(f"  ‚ùå Failed to parse search results: {str(e)}")
        
        return repos
    
    def _discover_related_repositories(self, topic: str, max_results: int) -> List[RepositoryProfile]:
        """Discover related repositories from known high-quality ones"""
        print(f"  üîó Discovering related repositories for: {topic}")
        
        # Get known repositories from source registry
        known_repos = self._get_known_repositories_for_topic(topic)
        
        related_repos = []
        
        for repo in known_repos[:3]:  # Limit to avoid rate limits
            try:
                # Find repositories that are commonly starred together
                # or mentioned in the same contexts
                related = self._find_related_to_repository(repo, max_results // 3)
                related_repos.extend(related)
            except Exception as e:
                print(f"  ‚ùå Failed to find related repos for {repo}: {str(e)}")
        
        return related_repos
    
    def _get_known_repositories_for_topic(self, topic: str) -> List[str]:
        """Get known high-quality repositories for topic from registry"""
        github_sources = self.source_registry.get('github_sources', {})
        official_repos = github_sources.get('official_repositories', {}).get('sources', [])
        
        relevant_repos = []
        for repo in official_repos:
            repo_topics = repo.get('topics', [])
            if any(topic.lower() in repo_topic.lower() for repo_topic in repo_topics):
                relevant_repos.append(repo['url'])
        
        return relevant_repos
    
    def _find_related_to_repository(self, repo_url: str, max_results: int) -> List[RepositoryProfile]:
        """Find repositories related to a known good repository"""
        # This would use GitHub's API to find related repositories
        # For now, return empty list as placeholder
        return []
    
    def _deduplicate_repositories(self, repos: List[RepositoryProfile]) -> List[RepositoryProfile]:
        """Remove duplicate repositories"""
        seen_urls = set()
        unique_repos = []
        
        for repo in repos:
            if repo.url not in seen_urls:
                seen_urls.add(repo.url)
                unique_repos.append(repo)
        
        return unique_repos
    
    def _rank_repositories(self, repos: List[RepositoryProfile], topic: str) -> List[RepositoryProfile]:
        """Rank repositories by quality and relevance"""
        
        def calculate_final_score(repo: RepositoryProfile) -> float:
            # Base authority score
            score = repo.authority_score * 0.4
            
            # Relevance score
            score += repo.relevance_score * 0.3
            
            # User preference adjustment
            user_pref = self._get_user_preference_for_repo(repo, topic)
            score += user_pref * 0.2
            
            # Quality indicators
            quality_bonus = self._calculate_quality_bonus(repo)
            score += quality_bonus * 0.1
            
            return min(score, 1.0)
        
        # Calculate final scores and sort
        for repo in repos:
            repo.final_score = calculate_final_score(repo)
        
        return sorted(repos, key=lambda r: r.final_score, reverse=True)
    
    def _get_user_preference_for_repo(self, repo: RepositoryProfile, topic: str) -> float:
        """Get user preference score for repository based on preferences"""
        
        # Check if it's an official source (high preference)
        if repo.quality_indicators.get('official', False):
            return 1.0
        
        # Check topic preferences
        topic_prefs = self.user_preferences.get('topic_preferences', {})
        if topic.lower() in topic_prefs:
            return topic_prefs[topic.lower()].get('interest_level', 0.6)
        
        # Check for language preferences
        stated_prefs = self.user_preferences.get('stated_preferences', {})
        if stated_prefs.get('official_sources', {}).get('preference_score', 0) > 0.8:
            if repo.quality_indicators.get('official', False):
                return 0.9
        
        return 0.6  # Default preference
    
    def _calculate_quality_bonus(self, repo: RepositoryProfile) -> float:
        """Calculate quality bonus based on indicators"""
        bonus = 0.0
        
        quality_indicators = repo.quality_indicators
        
        if quality_indicators.get('official', False):
            bonus += 0.3
        if quality_indicators.get('active', False):
            bonus += 0.2
        if quality_indicators.get('well_documented', False):
            bonus += 0.2
        if repo.stars > 10000:
            bonus += 0.1
        if repo.forks > 1000:
            bonus += 0.1
        
        return min(bonus, 1.0)
    
    def save_discovered_repositories(self, repos: List[RepositoryProfile], topic: str):
        """Save discovered repositories to unified knowledge vault"""
        
        # Create discovery results directory
        discovery_dir = self.base_path / "knowledge-vault" / "github-discovery"
        discovery_dir.mkdir(parents=True, exist_ok=True)
        
        # Save discovery results
        timestamp = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')
        results_file = discovery_dir / f"{topic}_{timestamp}_discovery.json"
        
        discovery_results = {
            "discovery_metadata": {
                "topic": topic,
                "timestamp": datetime.now(timezone.utc).isoformat(),
                "algorithm_version": "1.0.0",
                "repositories_discovered": len(repos)
            },
            "repositories": [asdict(repo) for repo in repos],
            "summary": {
                "top_repository": repos[0].name if repos else None,
                "average_authority_score": sum(r.authority_score for r in repos) / len(repos) if repos else 0,
                "official_repositories": len([r for r in repos if r.quality_indicators.get('official', False)])
            }
        }
        
        with open(results_file, 'w') as f:
            json.dump(discovery_results, f, indent=2)
        
        print(f"üíæ Saved {len(repos)} discovered repositories to: {results_file}")
        
        # Update source registry with new discoveries
        self._update_source_registry_with_discoveries(repos, topic)
    
    def _update_source_registry_with_discoveries(self, repos: List[RepositoryProfile], topic: str):
        """Update source registry with newly discovered high-quality repositories"""
        
        high_quality_repos = [r for r in repos if r.authority_score > 0.8 and r.final_score > 0.7]
        
        if not high_quality_repos:
            return
        
        print(f"üìù Adding {len(high_quality_repos)} high-quality repositories to source registry")
        
        # This would update the source registry YAML file
        # For now, just log what would be added
        for repo in high_quality_repos:
            print(f"  + {repo.name} (Score: {repo.final_score:.3f})")

def main():
    """Main entry point for GitHub discovery"""
    discovery = GitHubDiscoveryAlgorithm()
    
    # Example discoveries
    topics = ["react", "typescript", "python"]
    
    for topic in topics:
        print(f"\nüöÄ Starting GitHub discovery for: {topic}")
        print("=" * 50)
        
        repos = discovery.discover_repositories_for_topic(topic, max_results=5)
        discovery.save_discovered_repositories(repos, topic)
        
        print(f"‚úÖ Discovered {len(repos)} repositories for {topic}")

if __name__ == "__main__":
    main()